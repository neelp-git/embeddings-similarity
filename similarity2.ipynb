{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "jBuNwooqmVij"
      },
      "source": [
        "# An Experiment with Embeddings, Vector Database, and Similarity Metrics (Part 2)\n",
        "\n",
        "Please refer to Part 1 [notebook](https://github.com/neelp-git/embeddings-similarity/blob/main/similarity.ipynb) and [blog post](https://medium.com/misc-posts/an-experiment-with-similarity-search-and-embeddings-6b015a8826fe) for the specifics of the dataset and queries.\n",
        "\n",
        "In this notebook, we store the embeddings in a vector database (Pinecone), and  query the dataset using the indexes on different similarity metrics.\n",
        "\n",
        "Embeddings:\n",
        "  - Hugging Face 'all-MiniLM-L6-v2'\n",
        "  - Open AI \"text-embedding-ada-002\"\n",
        "  - Open AI \"text-similarity-davinci-001\"\n",
        "\n",
        "Embeddings are stored and indexed in Pinecone vector database.\n",
        "\n",
        "Similarity functions:\n",
        "  - Cosine\n",
        "  - Dot product\n",
        "  - Euclidean distance\n",
        "\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "MX-nRH_BIB3W"
      },
      "source": [
        "## Helper functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "njV6linXITW2"
      },
      "outputs": [],
      "source": [
        "import pickle\n",
        "\n",
        "# save object to file\n",
        "def save(object, tofile):\n",
        "    with open(tofile, 'wb') as fp:\n",
        "        pickle.dump(object, fp)\n",
        "    return\n",
        "\n",
        "# load object from file\n",
        "def load(fromfile):\n",
        "    with open(fromfile, 'rb') as fp:\n",
        "        object = pickle.load(fp)\n",
        "    return object"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "9l3jaru7IiYv"
      },
      "source": [
        "## Load dataset and queries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JqHdUHb4IutE",
        "outputId": "6831557e-2e0d-486e-bef9-2a6deb5b3734"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "docs[0]: The car skidded to stop for the deer that stood frozen in the headlights of the car.\n",
            "query sentence 1: The deer froze in the headlights of the car.\n",
            "query sentence 2: Dream to solve world's problems.\n"
          ]
        }
      ],
      "source": [
        "datadir = 'data/'\n",
        "datadir = 'sample_data/'\n",
        "# load dataset and query sentences\n",
        "docs = load(datadir+'docs.pickle')\n",
        "print(f'docs[0]: {docs[0]}')\n",
        "q1_sentence = load(datadir+'q1.pickle')\n",
        "print(f'query sentence 1: {q1_sentence}')\n",
        "q2_sentence = load(datadir+'q2.pickle')\n",
        "print(f'query sentence 2: {q2_sentence}')"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "leSjbrsGHA4-"
      },
      "source": [
        "## Embeddings with `all-MiniLM-L6-v2`"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "gjfiggoHIZDN"
      },
      "source": [
        "### Load saved embeddings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yi59Tn2RI7d0",
        "outputId": "81f370b3-4449-407d-8e75-d0cc95c75659"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dataset embeddings loaded.\n",
            "shape: torch.Size([57, 384])\n"
          ]
        }
      ],
      "source": [
        "text_embedding_model = 'all-MiniLM-L6-v2'\n",
        "docs_file = f'{datadir}docs-{text_embedding_model}.pickle'\n",
        "\n",
        "try:\n",
        "  doc_embeddings = load(docs_file)\n",
        "  doc_embeddings_list = doc_embeddings.tolist()\n",
        "  print('Dataset embeddings loaded.')\n",
        "  print(f'shape: {doc_embeddings.shape}')\n",
        "\n",
        "except e:\n",
        "  print(f'Exception: {e}. Use Part 1 ntoebook to generate these embeddings.')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hwL146qGVOHb",
        "outputId": "cf004a8e-79bd-4d59-f3cc-4fa52b6c8450"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Query embeddings loaded.\n",
            "shape: torch.Size([384])\n"
          ]
        }
      ],
      "source": [
        "q1_file = f'{datadir}q1-{text_embedding_model}.pickle'\n",
        "q2_file = f'{datadir}q2-{text_embedding_model}.pickle'\n",
        "\n",
        "try:\n",
        "  q1_embeddings = load(q1_file)\n",
        "  q2_embeddings = load(q2_file)\n",
        "  print('Query embeddings loaded.')\n",
        "  print(f'shape: {q1_embeddings.shape}')\n",
        "\n",
        "except e:\n",
        "  print(f'Exception: {e}. Use Part 1 ntoebook to generate these embeddings.')\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "j0TziinnOxUi"
      },
      "source": [
        "## Initialize the vector database"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BkySKQvmOfv8",
        "outputId": "c3ba6576-97a6-4257-e226-7b364ae71a0c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pinecone-client\n",
            "  Downloading pinecone_client-2.2.2-py3-none-any.whl (179 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m179.1/179.1 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from pinecone-client) (2.27.1)\n",
            "Requirement already satisfied: pyyaml>=5.4 in /usr/local/lib/python3.10/dist-packages (from pinecone-client) (6.0)\n",
            "Collecting loguru>=0.5.0 (from pinecone-client)\n",
            "  Downloading loguru-0.7.0-py3-none-any.whl (59 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.0/60.0 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: typing-extensions>=3.7.4 in /usr/local/lib/python3.10/dist-packages (from pinecone-client) (4.5.0)\n",
            "Collecting dnspython>=2.0.0 (from pinecone-client)\n",
            "  Downloading dnspython-2.3.0-py3-none-any.whl (283 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m283.7/283.7 kB\u001b[0m \u001b[31m14.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.10/dist-packages (from pinecone-client) (2.8.2)\n",
            "Requirement already satisfied: urllib3>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from pinecone-client) (1.26.15)\n",
            "Requirement already satisfied: tqdm>=4.64.1 in /usr/local/lib/python3.10/dist-packages (from pinecone-client) (4.65.0)\n",
            "Requirement already satisfied: numpy>=1.22.0 in /usr/local/lib/python3.10/dist-packages (from pinecone-client) (1.22.4)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.5.3->pinecone-client) (1.16.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pinecone-client) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pinecone-client) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pinecone-client) (3.4)\n",
            "Installing collected packages: loguru, dnspython, pinecone-client\n",
            "Successfully installed dnspython-2.3.0 loguru-0.7.0 pinecone-client-2.2.2\n"
          ]
        }
      ],
      "source": [
        "#!pip install \"pinecone-client[grpc]\"==2.2.1\n",
        "!pip3 install pinecone-client"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ui4Hgk4XneLm",
        "outputId": "b5bf9a5f-2a5a-4f13-e998-832af984befa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting python-dotenv\n",
            "  Downloading python_dotenv-1.0.0-py3-none-any.whl (19 kB)\n",
            "Installing collected packages: python-dotenv\n",
            "Successfully installed python-dotenv-1.0.0\n"
          ]
        }
      ],
      "source": [
        "!pip3 install python-dotenv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k0efuwF6noMT"
      },
      "outputs": [],
      "source": [
        "from dotenv import dotenv_values\n",
        "\n",
        "#config = dotenv_values(\".env\")\n",
        "#pineconse_api_key = config['PINECONE_API_KEY']\n",
        "#pineconse_env = config['PINECONE_ENVIRONMENT']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M4Djyr1yOfwK",
        "outputId": "a7690ae4-06ef-4bd1-9625-f5cfc67375e5"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pinecone/index.py:4: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
            "  from tqdm.autonotebook import tqdm\n"
          ]
        }
      ],
      "source": [
        "import pinecone\n",
        "\n",
        "pinecone.init(\n",
        "    api_key=pineconse_api_key,\n",
        "    environment=pineconse_env\n",
        ")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "feH_Ai2EPi1l"
      },
      "source": [
        "## Indexes, similarity searches, and comparisons\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FTHel-XrQR71"
      },
      "outputs": [],
      "source": [
        "# convenience functions to create and populate indexes in pinecone\n",
        "\n",
        "pinecone_index = None\n",
        "def create_index(index_to_create, dimension, metric):\n",
        "  # only create index if it doesn't exist\n",
        "  if index_to_create not in pinecone.list_indexes():\n",
        "      pinecone.create_index(\n",
        "          name=index_to_create,\n",
        "          dimension=dimension,\n",
        "          metric=metric\n",
        "      )\n",
        "  return\n",
        "\n",
        "def delete_index(index_name):\n",
        "  pinecone.delete_index(index_name)\n",
        "\n",
        "def populate_index(index_name, upsert_docs):\n",
        "  global pinecone_index\n",
        "  pinecone_index = pinecone.Index(index_name)\n",
        "  return pinecone_index.upsert(upsert_docs)\n",
        "\n",
        "def query_index(q_embeddings):\n",
        "  # submit query\n",
        "  xc = pinecone_index.query(q_embeddings, top_k=7, include_metadata=True)\n",
        "  print(*[docs[int(xc['matches'][i]['id'])] for i in range(len(xc['matches']))], sep='\\n')\n",
        "  return"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zU7ZaAHETjwv"
      },
      "outputs": [],
      "source": [
        "docs_to_upsert = [(str(i), de.tolist()) for i, de in enumerate(doc_embeddings)]"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "xuwTC4_VPi1m"
      },
      "source": [
        "### Cosine similarity search and results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K-pldyyZKdaY",
        "outputId": "6f630d2c-04f7-47f8-ecbc-5950efd5ea21"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'upserted_count': 57}"
            ]
          },
          "execution_count": 67,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "index_name = 'minilm-cosine'\n",
        "create_index(index_name, len(doc_embeddings_list[0]), 'cosine')\n",
        "populate_index(index_name, docs_to_upsert)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KEkVwZ0dVOHb",
        "outputId": "e841484a-2fa4-482e-d173-622e0e835b66"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The car skidded and stopped for the frozen deer in its headlights.\n",
            "The car skidded to stop for the deer that stood frozen in the headlights of the car.\n",
            "The car skidded to a standstill for the deer that remained motionless in the car's headlights.\n",
            "The car skidded and stopped to avoid the motionless deer illuminated by its headlights.\n",
            "The vehicle slid and came to a halt in response to the deer's immobility under the car's headlights.\n",
            "The scientific article explains what causes animals to freeze staring into the headlights of speeding vehicles causing many deaths and accidents every year.\n",
            "As the car lost traction, it slid across the road and eventually halted abruptly, its brakes screeching, due to the presence of a motionless deer standing in the direct path of its headlights.\n"
          ]
        }
      ],
      "source": [
        "query_index(q1_embeddings.tolist())"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "sOnzB3vobVkx"
      },
      "source": [
        "5 out of top 6 results are the expected semantically similar results. Acccuracy: 5/6 = 83%.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LnD6C478a9dd",
        "outputId": "02249985-a056-4351-edab-3db1bf4a71d7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The 16-year-old genius, having earned a PhD, contemplated global challenges and recognized science as the solution.\n",
            "Having completed his doctorate at 16, the exceptionally gifted young prodigy pondered the difficulties confronting the world, intuitively perceiving science as the remedy.\n",
            "Having finished his PhD at 16, the boy genius  contemplated the challenges the world faced, and intuited that science must be the solution.\n",
            "The boy genius finished his PhD at 16 and believed science was the solution to the world's challenges.\n",
            "After completing his PhD at the age of 16, the exceptionally talented young prodigy reflected on the global challenges and recognized science as the answer.\n",
            "Finding sustainable energy solutions is crucial for a greener future.\n",
            "Having successfully obtained his PhD at the remarkably young age of 16, the boy genius engaged in deep contemplation of the complex issues faced by the world. His intuition led him to firmly believe that science held the key to addressing these challenges, further fueling his dedication to scientific pursuits.\n"
          ]
        }
      ],
      "source": [
        "query_index(q2_embeddings.tolist())"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "eSlwZr8UbZ6i"
      },
      "source": [
        "5 out of top 6 results are the expected semantically similar results. Acccuracy: 5/6 = 83%.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Jsujsosga3OO"
      },
      "outputs": [],
      "source": [
        "delete_index('minilm-cosine')"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "guw2ZiT2d01f"
      },
      "source": [
        "### Euclidean Distance similarity search and results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zb49ghKNd01g",
        "outputId": "55e3abe6-078c-4244-d96a-6d0cc8775785"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'upserted_count': 57}"
            ]
          },
          "execution_count": 104,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "index_name = 'minilm-euclidean'\n",
        "create_index(index_name, len(doc_embeddings_list[0]), 'euclidean')\n",
        "populate_index(index_name, docs_to_upsert)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r6xBSpkId01g",
        "outputId": "ff0b9ed9-11e1-4c03-9536-cf2307e90450"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The car skidded and stopped for the frozen deer in its headlights.\n",
            "The car skidded to stop for the deer that stood frozen in the headlights of the car.\n",
            "The car skidded to a standstill for the deer that remained motionless in the car's headlights.\n",
            "The car skidded and stopped to avoid the motionless deer illuminated by its headlights.\n",
            "The vehicle slid and came to a halt in response to the deer's immobility under the car's headlights.\n",
            "The scientific article explains what causes animals to freeze staring into the headlights of speeding vehicles causing many deaths and accidents every year.\n",
            "As the car lost traction, it slid across the road and eventually halted abruptly, its brakes screeching, due to the presence of a motionless deer standing in the direct path of its headlights.\n"
          ]
        }
      ],
      "source": [
        "query_index(q1_embeddings.tolist())"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "Z8dXm_SFd01g"
      },
      "source": [
        "5 out of top 6 results are the expected semantically similar results. Acccuracy: 5/6 = 83%.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wu0SjAJud01h",
        "outputId": "a8f86e4d-0059-48bc-dcbc-12c4d33dfc13"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The 16-year-old genius, having earned a PhD, contemplated global challenges and recognized science as the solution.\n",
            "Having completed his doctorate at 16, the exceptionally gifted young prodigy pondered the difficulties confronting the world, intuitively perceiving science as the remedy.\n",
            "Having finished his PhD at 16, the boy genius  contemplated the challenges the world faced, and intuited that science must be the solution.\n",
            "The boy genius finished his PhD at 16 and believed science was the solution to the world's challenges.\n",
            "After completing his PhD at the age of 16, the exceptionally talented young prodigy reflected on the global challenges and recognized science as the answer.\n",
            "Finding sustainable energy solutions is crucial for a greener future.\n",
            "Having successfully obtained his PhD at the remarkably young age of 16, the boy genius engaged in deep contemplation of the complex issues faced by the world. His intuition led him to firmly believe that science held the key to addressing these challenges, further fueling his dedication to scientific pursuits.\n"
          ]
        }
      ],
      "source": [
        "query_index(q2_embeddings.tolist())"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "qLDhM3xSd01h"
      },
      "source": [
        "5 out of top 6 results are the expected semantically similar results. Acccuracy: 5/6 = 83%.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TVzwHKMZd01h"
      },
      "outputs": [],
      "source": [
        "delete_index('minilm-euclidean')"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "QXhOoqUzYHNJ"
      },
      "source": [
        "### Dot Product similarity search and results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jftwzkbqYE6s",
        "outputId": "07825dad-3869-4cb0-e61b-229f7cc44460"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'upserted_count': 57}"
            ]
          },
          "execution_count": 94,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "index_name = 'minilm-dotproduct'\n",
        "create_index(index_name, len(doc_embeddings_list[0]), 'dotproduct')\n",
        "populate_index(index_name, docs_to_upsert)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sIz_CvG_bzlF",
        "outputId": "c6d54505-4893-457b-c3be-2afb77695220"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The car skidded and stopped for the frozen deer in its headlights.\n",
            "The car skidded to stop for the deer that stood frozen in the headlights of the car.\n",
            "The car skidded to a standstill for the deer that remained motionless in the car's headlights.\n",
            "The car skidded and stopped to avoid the motionless deer illuminated by its headlights.\n",
            "The vehicle slid and came to a halt in response to the deer's immobility under the car's headlights.\n",
            "The scientific article explains what causes animals to freeze staring into the headlights of speeding vehicles causing many deaths and accidents every year.\n",
            "As the car lost traction, it slid across the road and eventually halted abruptly, its brakes screeching, due to the presence of a motionless deer standing in the direct path of its headlights.\n"
          ]
        }
      ],
      "source": [
        "query_index(q1_embeddings.tolist())"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "cTWYQrvrbzlG"
      },
      "source": [
        "5 out of top 6 results are the expected semantically similar results. Acccuracy: 5/6 = 83%.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZRwdLCvubzlG",
        "outputId": "b4b29aab-11f7-4299-942d-56c1f73738fb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The 16-year-old genius, having earned a PhD, contemplated global challenges and recognized science as the solution.\n",
            "Having completed his doctorate at 16, the exceptionally gifted young prodigy pondered the difficulties confronting the world, intuitively perceiving science as the remedy.\n",
            "Having finished his PhD at 16, the boy genius  contemplated the challenges the world faced, and intuited that science must be the solution.\n",
            "The boy genius finished his PhD at 16 and believed science was the solution to the world's challenges.\n",
            "After completing his PhD at the age of 16, the exceptionally talented young prodigy reflected on the global challenges and recognized science as the answer.\n",
            "Finding sustainable energy solutions is crucial for a greener future.\n",
            "Having successfully obtained his PhD at the remarkably young age of 16, the boy genius engaged in deep contemplation of the complex issues faced by the world. His intuition led him to firmly believe that science held the key to addressing these challenges, further fueling his dedication to scientific pursuits.\n"
          ]
        }
      ],
      "source": [
        "query_index(q2_embeddings.tolist())"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "2J5RQj2NbzlG"
      },
      "source": [
        "5 out of top 6 results are the expected semantically similar results. Acccuracy: 5/6 = 83%.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6ZivwChjbzlG"
      },
      "outputs": [],
      "source": [
        "delete_index('minilm-dotproduct')"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "rGpl9CTThZ1G"
      },
      "source": [
        "## Embeddings with `text-embedding-ada-002`"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "wEqdn0kLUbQY"
      },
      "source": [
        "### Initialize openai"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dXpouwWkUzxu",
        "outputId": "90d08d17-020b-41a1-b587-f86206e175d7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting langchain\n",
            "  Downloading langchain-0.0.203-py3-none-any.whl (1.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m14.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting openai\n",
            "  Downloading openai-0.27.8-py3-none-any.whl (73 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m73.6/73.6 kB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tiktoken\n",
            "  Downloading tiktoken-0.4.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m57.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: PyYAML>=5.4.1 in /usr/local/lib/python3.10/dist-packages (from langchain) (6.0)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.0.10)\n",
            "Collecting aiohttp<4.0.0,>=3.8.3 (from langchain)\n",
            "  Downloading aiohttp-3.8.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m45.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting async-timeout<5.0.0,>=4.0.0 (from langchain)\n",
            "  Downloading async_timeout-4.0.2-py3-none-any.whl (5.8 kB)\n",
            "Collecting dataclasses-json<0.6.0,>=0.5.7 (from langchain)\n",
            "  Downloading dataclasses_json-0.5.8-py3-none-any.whl (26 kB)\n",
            "Collecting langchainplus-sdk>=0.0.9 (from langchain)\n",
            "  Downloading langchainplus_sdk-0.0.10-py3-none-any.whl (21 kB)\n",
            "Requirement already satisfied: numexpr<3.0.0,>=2.8.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.8.4)\n",
            "Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.22.4)\n",
            "Collecting openapi-schema-pydantic<2.0,>=1.2 (from langchain)\n",
            "  Downloading openapi_schema_pydantic-1.2.4-py3-none-any.whl (90 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m90.0/90.0 kB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pydantic<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.10.7)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.27.1)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (8.2.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai) (4.65.0)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken) (2022.10.31)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (2.0.12)\n",
            "Collecting multidict<7.0,>=4.5 (from aiohttp<4.0.0,>=3.8.3->langchain)\n",
            "  Downloading multidict-6.0.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (114 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.5/114.5 kB\u001b[0m \u001b[31m11.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting yarl<2.0,>=1.0 (from aiohttp<4.0.0,>=3.8.3->langchain)\n",
            "  Downloading yarl-1.9.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (268 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m268.8/268.8 kB\u001b[0m \u001b[31m21.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting frozenlist>=1.1.1 (from aiohttp<4.0.0,>=3.8.3->langchain)\n",
            "  Downloading frozenlist-1.3.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (149 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m149.6/149.6 kB\u001b[0m \u001b[31m13.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting aiosignal>=1.1.2 (from aiohttp<4.0.0,>=3.8.3->langchain)\n",
            "  Downloading aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
            "Collecting marshmallow<4.0.0,>=3.3.0 (from dataclasses-json<0.6.0,>=0.5.7->langchain)\n",
            "  Downloading marshmallow-3.19.0-py3-none-any.whl (49 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.1/49.1 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting marshmallow-enum<2.0.0,>=1.5.1 (from dataclasses-json<0.6.0,>=0.5.7->langchain)\n",
            "  Downloading marshmallow_enum-1.5.1-py2.py3-none-any.whl (4.2 kB)\n",
            "Collecting typing-inspect>=0.4.0 (from dataclasses-json<0.6.0,>=0.5.7->langchain)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<2,>=1->langchain) (4.5.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2022.12.7)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.4)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (2.0.2)\n",
            "Requirement already satisfied: packaging>=17.0 in /usr/local/lib/python3.10/dist-packages (from marshmallow<4.0.0,>=3.3.0->dataclasses-json<0.6.0,>=0.5.7->langchain) (23.1)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect>=0.4.0->dataclasses-json<0.6.0,>=0.5.7->langchain)\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Installing collected packages: mypy-extensions, multidict, marshmallow, frozenlist, async-timeout, yarl, typing-inspect, tiktoken, openapi-schema-pydantic, marshmallow-enum, langchainplus-sdk, aiosignal, dataclasses-json, aiohttp, openai, langchain\n",
            "Successfully installed aiohttp-3.8.4 aiosignal-1.3.1 async-timeout-4.0.2 dataclasses-json-0.5.8 frozenlist-1.3.3 langchain-0.0.203 langchainplus-sdk-0.0.10 marshmallow-3.19.0 marshmallow-enum-1.5.1 multidict-6.0.4 mypy-extensions-1.0.0 openai-0.27.8 openapi-schema-pydantic-1.2.4 tiktoken-0.4.0 typing-inspect-0.9.0 yarl-1.9.2\n"
          ]
        }
      ],
      "source": [
        "!pip install langchain openai tiktoken"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "713NwqIFU2cI"
      },
      "outputs": [],
      "source": [
        "#config = dotenv_values(\".env\")\n",
        "#openai_api_key = config['OPENAI_API_KEY'] # \"get your token in http://hf.co/settings/tokens\""
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "V3rhtB_OUjMc"
      },
      "source": [
        "### Load or create dataset embeddings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eSEv6A5dVZUV",
        "outputId": "2aa4dd95-0753-4b53-d1f9-99c576059869"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "shape: 57x1536\n"
          ]
        }
      ],
      "source": [
        "text_embedding_model = \"text-embedding-ada-002\"\n",
        "docs_file = f'{datadir}docs-{text_embedding_model}.pickle'\n",
        "\n",
        "try:\n",
        "  doc_embeddings = load(docs_file)\n",
        "\n",
        "except:\n",
        "  # if not present, create and save\n",
        "  from langchain.embeddings import OpenAIEmbeddings\n",
        "  embeddings = OpenAIEmbeddings(openai_api_key=openai_api_key)\n",
        "  doc_embeddings = embeddings.embed_documents(docs)\n",
        "  save(doc_embeddings, docs_file)\n",
        "  \"\"\n",
        "print(f'shape: {len(doc_embeddings)}x{len(doc_embeddings[0])}')"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "zbKMDEbrUy54"
      },
      "source": [
        "### Load or create query sentence embeddings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lcXleTOzU-Wz",
        "outputId": "767238ec-b20d-4f7d-b2d7-1d5fa3f8aa32"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "size: 1536\n"
          ]
        }
      ],
      "source": [
        "q1_file = f'{datadir}q1-{text_embedding_model}.pickle'\n",
        "q2_file = f'{datadir}q2-{text_embedding_model}.pickle'\n",
        "\n",
        "try:\n",
        "  q1_embeddings = load(q1_file)\n",
        "  q2_embeddings = load(q2_file)\n",
        "\n",
        "except:\n",
        "  # if not present, create and save\n",
        "  from langchain.embeddings import OpenAIEmbeddings\n",
        "  embeddings = OpenAIEmbeddings(openai_api_key=openai_api_key)\n",
        "  q1_embeddings = embeddings.embed_query(q1_sentence)\n",
        "  save(q1_embeddings, q1_file)\n",
        "  q2_embeddings = embeddings.embed_query(q2_sentence)\n",
        "  save(q2_embeddings, q2_file)\n",
        "\n",
        "print(f'size: {len(q1_embeddings)}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TfLmPeaLTaje"
      },
      "outputs": [],
      "source": [
        "docs_to_upsert = [(str(i), de) for i, de in enumerate(doc_embeddings)]"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "2Yv8L4-JHboM"
      },
      "source": [
        "## Store embeddings in a vector database and perform similarity searches"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "la5dPRDbpMJa"
      },
      "source": [
        "### Cosine similarity search and results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nxIa_xVpRsAL",
        "outputId": "ea12d896-a4bb-4544-8854-06a2ed87b175"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'upserted_count': 57}"
            ]
          },
          "execution_count": 54,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "index_name = 'ada-cosine'\n",
        "create_index(index_name, len(doc_embeddings[0]), 'cosine')\n",
        "populate_index(index_name, docs_to_upsert)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0s00XdlrpMJh",
        "outputId": "250fd342-2e84-4195-aff3-ae5d2d550c54"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The car skidded to stop for the deer that stood frozen in the headlights of the car.\n",
            "The car skidded and stopped for the frozen deer in its headlights.\n",
            "The car skidded to a standstill for the deer that remained motionless in the car's headlights.\n",
            "The vehicle slid and came to a halt in response to the deer's immobility under the car's headlights.\n",
            "The car skidded and stopped to avoid the motionless deer illuminated by its headlights.\n",
            "As the car lost traction, it slid across the road and eventually halted abruptly, its brakes screeching, due to the presence of a motionless deer standing in the direct path of its headlights.\n",
            "The deer cautiously crossed the road, looking out for oncoming vehicles.\n"
          ]
        }
      ],
      "source": [
        "query_index(q1_embeddings)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "YI5tgUxkpMJh"
      },
      "source": [
        "6 out of top 6 results are the expected semantically similar results. Acccuracy: 6/6 = 100%.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1e2wtBjgpMJh",
        "outputId": "fb14b800-7bb0-4883-9acc-c90345ed534b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Having finished his PhD at 16, the boy genius  contemplated the challenges the world faced, and intuited that science must be the solution.\n",
            "The 16-year-old genius, having earned a PhD, contemplated global challenges and recognized science as the solution.\n",
            "The boy genius finished his PhD at 16 and believed science was the solution to the world's challenges.\n",
            "Having completed his doctorate at 16, the exceptionally gifted young prodigy pondered the difficulties confronting the world, intuitively perceiving science as the remedy.\n",
            "After completing his PhD at the age of 16, the exceptionally talented young prodigy reflected on the global challenges and recognized science as the answer.\n",
            "Finding sustainable energy solutions is crucial for a greener future.\n",
            "Access to clean water is a pressing global issue.\n"
          ]
        }
      ],
      "source": [
        "query_index(q2_embeddings)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "iR_QxmNSpMJi"
      },
      "source": [
        "5 out of top 6 results are the expected semantically similar results. Acccuracy: 5/6 = 83%.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZU8XcgBgpMJi"
      },
      "outputs": [],
      "source": [
        "delete_index('ada-cosine')"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "eTc1qoDhXwSt"
      },
      "source": [
        "### Euclidean Distance similarity search and results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QOgbjOMKXwS0",
        "outputId": "ea12d896-a4bb-4544-8854-06a2ed87b175"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'upserted_count': 57}"
            ]
          },
          "execution_count": 54,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "index_name = 'ada-euclidean'\n",
        "create_index(index_name, len(doc_embeddings[0]), 'euclidean')\n",
        "populate_index(index_name, docs_to_upsert)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O6yB2EVpXwS0",
        "outputId": "df75f396-1159-497d-a602-22b78bcbab1e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The car skidded to stop for the deer that stood frozen in the headlights of the car.\n",
            "The car skidded and stopped for the frozen deer in its headlights.\n",
            "The car skidded to a standstill for the deer that remained motionless in the car's headlights.\n",
            "The vehicle slid and came to a halt in response to the deer's immobility under the car's headlights.\n",
            "The car skidded and stopped to avoid the motionless deer illuminated by its headlights.\n",
            "As the car lost traction, it slid across the road and eventually halted abruptly, its brakes screeching, due to the presence of a motionless deer standing in the direct path of its headlights.\n",
            "The deer cautiously crossed the road, looking out for oncoming vehicles.\n"
          ]
        }
      ],
      "source": [
        "query_index(q1_embeddings)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "EaOd91h8XwS0"
      },
      "source": [
        "6 out of top 6 results are the expected semantically similar results. Acccuracy: 6/6 = 100%.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yCyMKvEVXwS1",
        "outputId": "61eb1d30-6b4c-4569-bfee-dde6ee34fd3f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Having finished his PhD at 16, the boy genius  contemplated the challenges the world faced, and intuited that science must be the solution.\n",
            "The 16-year-old genius, having earned a PhD, contemplated global challenges and recognized science as the solution.\n",
            "The boy genius finished his PhD at 16 and believed science was the solution to the world's challenges.\n",
            "Having completed his doctorate at 16, the exceptionally gifted young prodigy pondered the difficulties confronting the world, intuitively perceiving science as the remedy.\n",
            "After completing his PhD at the age of 16, the exceptionally talented young prodigy reflected on the global challenges and recognized science as the answer.\n",
            "Finding sustainable energy solutions is crucial for a greener future.\n",
            "Access to clean water is a pressing global issue.\n"
          ]
        }
      ],
      "source": [
        "query_index(q2_embeddings)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "mAObRNxbXwS1"
      },
      "source": [
        "5 out of top 6 results are the expected semantically similar results. Acccuracy: 5/6 = 83%.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xpslhg5_XwS1"
      },
      "outputs": [],
      "source": [
        "delete_index('ada-euclidean')"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "tujoHt5gnTUQ"
      },
      "source": [
        "### Dot Product similarity search and results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "utQT7lJ2nTUa",
        "outputId": "0b85f706-8dff-44f3-bd14-9df84a2394b2"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'upserted_count': 57}"
            ]
          },
          "execution_count": 35,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "index_name = 'ada-dotproduct'\n",
        "create_index(index_name, len(doc_embeddings[0]), 'dotproduct')\n",
        "populate_index(index_name, docs_to_upsert)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bbiMW9Z3nTUc",
        "outputId": "d787a1c1-f206-4b2b-e57a-46692ab168f4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The car skidded to stop for the deer that stood frozen in the headlights of the car.\n",
            "The car skidded and stopped for the frozen deer in its headlights.\n",
            "The car skidded to a standstill for the deer that remained motionless in the car's headlights.\n",
            "The vehicle slid and came to a halt in response to the deer's immobility under the car's headlights.\n",
            "The car skidded and stopped to avoid the motionless deer illuminated by its headlights.\n",
            "As the car lost traction, it slid across the road and eventually halted abruptly, its brakes screeching, due to the presence of a motionless deer standing in the direct path of its headlights.\n",
            "The deer cautiously crossed the road, looking out for oncoming vehicles.\n"
          ]
        }
      ],
      "source": [
        "query_index(q1_embeddings)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "AKsr_kcrnTUd"
      },
      "source": [
        "6 out of top 6 results are the expected semantically similar results. Acccuracy: 6/6 = 100%.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bcnOPgj2nTUd",
        "outputId": "bdf2b33e-a723-4433-8570-85a4c72fd75f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Having finished his PhD at 16, the boy genius  contemplated the challenges the world faced, and intuited that science must be the solution.\n",
            "The 16-year-old genius, having earned a PhD, contemplated global challenges and recognized science as the solution.\n",
            "The boy genius finished his PhD at 16 and believed science was the solution to the world's challenges.\n",
            "Having completed his doctorate at 16, the exceptionally gifted young prodigy pondered the difficulties confronting the world, intuitively perceiving science as the remedy.\n",
            "After completing his PhD at the age of 16, the exceptionally talented young prodigy reflected on the global challenges and recognized science as the answer.\n",
            "Finding sustainable energy solutions is crucial for a greener future.\n",
            "Access to clean water is a pressing global issue.\n"
          ]
        }
      ],
      "source": [
        "query_index(q2_embeddings)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "aw2XEeuOnTUf"
      },
      "source": [
        "5 out of top 6 results are the expected semantically similar results. Acccuracy: 5/6 = 83%.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tF-OQAJRnTUf"
      },
      "outputs": [],
      "source": [
        "delete_index('ada-dotproduct')"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "AZ8v_MrUQXDU"
      },
      "source": [
        "## Embeddings with `text-similarity-davinci-001`"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "j6jlbwq0QXDj"
      },
      "source": [
        "### Load or create dataset embeddings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iAj2VxY2QXDj",
        "outputId": "420aece8-e833-4416-b4dc-b5836b1c3fcc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "shape: 57x12288\n"
          ]
        }
      ],
      "source": [
        "text_embedding_model = \"text-similarity-davinci-001\"\n",
        "docs_file = f'{datadir}docs-{text_embedding_model}.pickle'\n",
        "\n",
        "try:\n",
        "  doc_embeddings = load(docs_file)\n",
        "\n",
        "except:\n",
        "  # if not present, create and save\n",
        "  import openai\n",
        "  openai.api_key = openai_api_key\n",
        "  doc_embeddings = []\n",
        "  for doc in docs:\n",
        "    embeddings = openai.Embedding.create(input = [doc], model=text_embedding_model)['data'][0]['embedding']\n",
        "    doc_embeddings.append(embeddings)\n",
        "  save(doc_embeddings, docs_file)\n",
        "\n",
        "print(f'shape: {len(doc_embeddings)}x{len(doc_embeddings[0])}')"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "lW0AYD2tQXDj"
      },
      "source": [
        "### Load or create query sentence embeddings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uLWMnLcPQXDj",
        "outputId": "77a5f774-3acb-470f-99db-dc2ca0212473"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "size: 12288\n"
          ]
        }
      ],
      "source": [
        "q1_file = f'{datadir}q1-{text_embedding_model}.pickle'\n",
        "q2_file = f'{datadir}q2-{text_embedding_model}.pickle'\n",
        "\n",
        "try:\n",
        "  q1_embeddings = load(q1_file)\n",
        "  q2_embeddings = load(q2_file)\n",
        "\n",
        "except:\n",
        "  # if not present, create and save\n",
        "  q1_embeddings = openai.Embedding.create(input = [q1_sentence], model=text_embedding_model)['data'][0]['embedding']\n",
        "  save(q1_embeddings, q1_file)\n",
        "  q2_embeddings = openai.Embedding.create(input = [q2_sentence], model=text_embedding_model)['data'][0]['embedding']\n",
        "  save(q2_embeddings, q2_file)\n",
        "\n",
        "print(f'size: {len(q1_embeddings)}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f4v8_FZmQXDk"
      },
      "outputs": [],
      "source": [
        "docs_to_upsert = [(str(i), de) for i, de in enumerate(doc_embeddings)]"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "mQFMkwVvQXDk"
      },
      "source": [
        "## Store embeddings in a vector database and perform similarity searches\n",
        "Note: We could not create an index in the free tier of Pinecone service as the large size of \"text-similarity-davinci-001\" embeddings exceeds the alotted free tier capacity. Therefore, we resort to in-memory computations on the embeddings using the numpy similarity functions."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "VzHoiPeiQXDk"
      },
      "source": [
        "### Cosine similarity search and results\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S2_9e0iE5rSX",
        "outputId": "a04dac9b-e1d8-46e6-f7b9-d9ea16c2b43d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting sentence-transformers\n",
            "  Downloading sentence-transformers-2.2.2.tar.gz (85 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.0/86.0 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting transformers<5.0.0,>=4.6.0 (from sentence-transformers)\n",
            "  Downloading transformers-4.30.2-py3-none-any.whl (7.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.2/7.2 MB\u001b[0m \u001b[31m61.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (4.65.0)\n",
            "Requirement already satisfied: torch>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (2.0.1+cu118)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (0.15.2+cu118)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (1.22.4)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (1.2.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (1.10.1)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (3.8.1)\n",
            "Collecting sentencepiece (from sentence-transformers)\n",
            "  Downloading sentencepiece-0.1.99-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m60.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting huggingface-hub>=0.4.0 (from sentence-transformers)\n",
            "  Downloading huggingface_hub-0.15.1-py3-none-any.whl (236 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m236.8/236.8 kB\u001b[0m \u001b[31m20.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.4.0->sentence-transformers) (3.12.0)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.4.0->sentence-transformers) (2023.4.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.4.0->sentence-transformers) (2.27.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.4.0->sentence-transformers) (6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.4.0->sentence-transformers) (4.5.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.4.0->sentence-transformers) (23.1)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->sentence-transformers) (1.11.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->sentence-transformers) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->sentence-transformers) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->sentence-transformers) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.6.0->sentence-transformers) (3.25.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.6.0->sentence-transformers) (16.0.5)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (2022.10.31)\n",
            "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1 (from transformers<5.0.0,>=4.6.0->sentence-transformers)\n",
            "  Downloading tokenizers-0.13.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m94.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting safetensors>=0.3.1 (from transformers<5.0.0,>=4.6.0->sentence-transformers)\n",
            "  Downloading safetensors-0.3.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m46.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk->sentence-transformers) (8.1.3)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk->sentence-transformers) (1.2.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence-transformers) (3.1.0)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision->sentence-transformers) (8.4.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.6.0->sentence-transformers) (2.1.2)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (3.4)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.6.0->sentence-transformers) (1.3.0)\n",
            "Building wheels for collected packages: sentence-transformers\n",
            "  Building wheel for sentence-transformers (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sentence-transformers: filename=sentence_transformers-2.2.2-py3-none-any.whl size=125926 sha256=11ef3a8e808433096a0c0eff017a299fdcd72d2942177044439b707cc0369eb5\n",
            "  Stored in directory: /root/.cache/pip/wheels/62/f2/10/1e606fd5f02395388f74e7462910fe851042f97238cbbd902f\n",
            "Successfully built sentence-transformers\n",
            "Installing collected packages: tokenizers, sentencepiece, safetensors, huggingface-hub, transformers, sentence-transformers\n",
            "Successfully installed huggingface-hub-0.15.1 safetensors-0.3.1 sentence-transformers-2.2.2 sentencepiece-0.1.99 tokenizers-0.13.3 transformers-4.30.2\n"
          ]
        }
      ],
      "source": [
        "!pip install -U sentence-transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "6FdhtXkTWF1u"
      },
      "outputs": [],
      "source": [
        "from sentence_transformers.util import semantic_search, cos_sim, dot_score\n",
        "doc_embeddings_tensors = [torch.FloatTensor(de) for de in doc_embeddings]\n",
        "hits1 = semantic_search(torch.FloatTensor(q1_embeddings), doc_embeddings_tensors, top_k=7, score_function=cos_sim)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "iKF63XsZ3_gl"
      },
      "source": [
        "Query sentence 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-neAMMaP6-mq",
        "outputId": "0a019c47-b9e2-4113-fbd4-e19f3693aad7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The car skidded and stopped for the frozen deer in its headlights.\n",
            "The car skidded to stop for the deer that stood frozen in the headlights of the car.\n",
            "The car skidded to a standstill for the deer that remained motionless in the car's headlights.\n",
            "The vehicle slid and came to a halt in response to the deer's immobility under the car's headlights.\n",
            "The car skidded and stopped to avoid the motionless deer illuminated by its headlights.\n",
            "The deer cautiously crossed the road, looking out for oncoming vehicles.\n",
            "The majestic deer stood still, observing its surroundings.\n"
          ]
        }
      ],
      "source": [
        "print(*[docs[hits1[0][i]['corpus_id']] for i in range(len(hits1[0]))], sep='\\n')"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "3HA2Zj104Ds0"
      },
      "source": [
        "Query sentence 2\n",
        "\n",
        "Note, none of the expected similar results are returned."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "RmVd7RqJ7K03"
      },
      "outputs": [],
      "source": [
        "hits2 = semantic_search(torch.FloatTensor(q2_embeddings), doc_embeddings_tensors, top_k=7, score_function=cos_sim)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FVy995vw7T_j",
        "outputId": "42cc2057-bd2b-43a4-8555-808dd3344c58"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Finding sustainable energy solutions is crucial for a greener future.\n",
            "Access to clean water is a pressing global issue.\n",
            "The fight against inequality and social injustice persists.\n",
            "Climate change poses a grave threat to our planet.\n",
            "The invention of the internet connected the world like never before.\n",
            "Political instability continues to disrupt nations worldwide.\n",
            "The invention of the computer paved the way for the digital age.\n"
          ]
        }
      ],
      "source": [
        "print(*[docs[hits2[0][i]['corpus_id']] for i in range(len(hits2[0]))], sep='\\n')"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "Qofh9xpd4Lzh"
      },
      "source": [
        "### Euclidean Distance similarity search and results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "pLM0oIzUUpZF"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "N = len(doc_embeddings)\n",
        "d = len(doc_embeddings[0])\n",
        "k = 7 # #top k\n",
        "# create an array of N d-dimensional vectors (the search space)\n",
        "S = np.array(doc_embeddings)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "o6tDfEdu4ZsE"
      },
      "source": [
        "Query sentence 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8Tm_yN02T20A",
        "outputId": "5e0c6784-6ac6-404e-e8aa-6b99e08e816e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The car skidded and stopped for the frozen deer in its headlights.\n",
            "The car skidded to stop for the deer that stood frozen in the headlights of the car.\n",
            "The car skidded to a standstill for the deer that remained motionless in the car's headlights.\n",
            "The vehicle slid and came to a halt in response to the deer's immobility under the car's headlights.\n",
            "The car skidded and stopped to avoid the motionless deer illuminated by its headlights.\n",
            "The deer cautiously crossed the road, looking out for oncoming vehicles.\n",
            "The majestic deer stood still, observing its surroundings.\n"
          ]
        }
      ],
      "source": [
        "# query 1\n",
        "# create a d-dimensional query vector\n",
        "x = np.array(q1_embeddings)\n",
        "# compute distances\n",
        "distances = np.linalg.norm(S - x, axis = 1)\n",
        "# select indices of vectors having the lowest distances from the X\n",
        "neighbours = np.argpartition(distances, range(0, k))[:k]\n",
        "print(*[docs[neighbours[i]] for i in range(len(neighbours))], sep='\\n')"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "QLkqYr9c4cR6"
      },
      "source": [
        "Query sentence 2\n",
        "\n",
        "Note, none of the expected similar results are returned."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A92i6iHb-GDR",
        "outputId": "d1f840e0-8a19-449a-f578-c3805622e351"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Finding sustainable energy solutions is crucial for a greener future.\n",
            "Access to clean water is a pressing global issue.\n",
            "The fight against inequality and social injustice persists.\n",
            "Climate change poses a grave threat to our planet.\n",
            "The invention of the internet connected the world like never before.\n",
            "Political instability continues to disrupt nations worldwide.\n",
            "The invention of the computer paved the way for the digital age.\n"
          ]
        }
      ],
      "source": [
        "# query 2\n",
        "# create a d-dimensional query vector\n",
        "x = np.array(q2_embeddings)\n",
        "# compute distances\n",
        "distances = np.linalg.norm(S - x, axis = 1)\n",
        "# select indices of vectors having the lowest distances from the X\n",
        "neighbours = np.argpartition(distances, range(0, k))[:k]\n",
        "print(*[docs[neighbours[i]] for i in range(len(neighbours))], sep='\\n')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
